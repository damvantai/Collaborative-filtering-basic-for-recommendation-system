{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Movielens dataset 100k movie ratings from 943 users and 1682 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading users file:\n",
    "user_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "# users = pd.read_csv('../data/ml-100k/u.user', sep='|', names=user_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading ratings file:\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "# ratings = pd.read_csv('../data/ml-100k/u.data', sep='\\t', names=rating_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading items file\n",
    "item_cols = ['movie_id', 'movie title', 'release data', 'video release date', 'IMDB URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drame', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "         'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "# items = pd.read_csv('../data/ml-100k/u.item', sep='|', names=item_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So user la:  943\n",
      "So bo phim la:  1682\n"
     ]
    }
   ],
   "source": [
    "# dem so user va so item\n",
    "n_users = 943\n",
    "n_items = 1682\n",
    "print(\"So user la: \", (n_users))\n",
    "print(\"So bo phim la: \", (n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bộ dữ liệu đã chia Movielen 100k đã chia săn thành 5 bộ dữ liệu trai-test \n",
    "\n",
    "# u1.base    -- The data sets u1.base and u1.test through u5.base and u5.test\n",
    "# u1.test       are 80%/20% splits of the u data into training and test data.\n",
    "# u2.base       Each of u1, ..., u5 have disjoint test sets; this if for\n",
    "# u2.test       5 fold cross validation (where you repeat your experiment\n",
    "# u3.base       with each training and test set and average the results).\n",
    "# u3.test       These data sets can be generated from u.data by mku.sh.\n",
    "# u4.base\n",
    "# u4.test\n",
    "# u5.base\n",
    "# u5.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_u1 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u1.base', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# train_u2 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u2.base', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# train_u3 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u3.base', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# train_u4 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u4.base', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "train_u5 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u5.base', sep='\\t', names=rating_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_u1 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u1.test', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# test_u2 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u2.test', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# test_u3 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u3.test', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "# test_u4 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u4.test', sep='\\t', names=rating_cols, encoding='latin-1')\n",
    "test_u5 = pd.read_csv('/home/damvantai/Documents/data/MovieLens/ml-100k/u5.test', sep='\\t', names=rating_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create matrix user-item rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo ma trận user-item, một cho training và một cho testing cho bo du lieu 2\n",
    "# train_matrix_u2 = np.zeros((n_users, n_items))\n",
    "# for line in train_u2.itertuples():\n",
    "#     # line[1]: user_id\n",
    "#     # line[2]: movie_id\n",
    "#     # line[3]: rating\n",
    "#     train_matrix_u2[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "# test_matrix_u2 = np.zeros((n_users, n_items))\n",
    "# for line in test_u2.itertuples():\n",
    "#     test_matrix_u2[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "# # tạo ma trận user-item, một cho training và một cho testing cho bo du lieu 3\n",
    "# train_matrix_u3 = np.zeros((n_users, n_items))\n",
    "# for line in train_u3.itertuples():\n",
    "#     # line[1]: user_id\n",
    "#     # line[2]: movie_id\n",
    "#     # line[3]: rating\n",
    "#     train_matrix_u3[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "# test_matrix_u3 = np.zeros((n_users, n_items))\n",
    "# for line in test_u3.itertuples():\n",
    "#     test_matrix_u3[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "# # tạo ma trận user-item, một cho training và một cho testing cho bo du lieu 4\n",
    "# train_matrix_u4 = np.zeros((n_users, n_items))\n",
    "# for line in train_u4.itertuples():\n",
    "#     # line[1]: user_id\n",
    "#     # line[2]: movie_id\n",
    "#     # line[3]: rating\n",
    "#     train_matrix_u4[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "# test_matrix_u4 = np.zeros((n_users, n_items))\n",
    "# for line in test_u4.itertuples():\n",
    "#     test_matrix_u4[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "# # tạo ma trận user-item, một cho training và một cho testing cho bo du lieu 1\n",
    "train_matrix_u5 = np.zeros((n_users, n_items))\n",
    "for line in train_u5.itertuples():\n",
    "    # line[1]: user_id\n",
    "    # line[2]: movie_id\n",
    "    # line[3]: rating\n",
    "    train_matrix_u5[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "test_matrix_u5 = np.zeros((n_users, n_items))\n",
    "for line in test_u5.itertuples():\n",
    "    test_matrix_u5[line[1]-1, line[2]-1] = line[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User function pairwise_distance calculate simarility item-item and user-user\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function predict to calculate matrix pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, category, metric):\n",
    "    \n",
    "    # user-user matrix similarity\n",
    "    if category == 'user':\n",
    "        \n",
    "        # Calculate matrix rating mean for user mean-user for rating item\n",
    "        mean_rating = np.zeros([943, 1])\n",
    "        for i in range(ratings.shape[0]):\n",
    "            sum = 0\n",
    "            num_elements = 0\n",
    "            for j in range(ratings.shape[1]):\n",
    "                if ratings[i][j] != 0:\n",
    "                    sum = sum + ratings[i][j]\n",
    "                    num_elements = num_elements + 1\n",
    "            mean_rating[i] = float(sum) / num_elements\n",
    "        \n",
    "        # Create matrix filled with mean rating from above\n",
    "        train_matrix_ratings_filled = np.array(ratings, copy=True)\n",
    "        for i in range(ratings.shape[0]):\n",
    "            for j in range(ratings.shape[1]):\n",
    "                if train_matrix_ratings_filled[i][j] == 0:\n",
    "                    train_matrix_ratings_filled[i][j] = mean_rating[i]\n",
    "                           \n",
    "        # Create matrix rating difference for matrix train filled and mean rating\n",
    "        rating_diff = train_matrix_ratings_filled - mean_rating\n",
    "        \n",
    "        # Metric similarity cosine or correlation\n",
    "        if metric == 'cosine':\n",
    "            similarity = 1 - pairwise_distances(rating_diff, metric='cosine')\n",
    "        elif metric == 'correlation':\n",
    "            similarity = 1 - pairwise_distances(rating_diff, metric='correlation')\n",
    "        \n",
    "        # Initialization matrix predict \n",
    "        pred = np.zeros([n_users, n_items])\n",
    "        \n",
    "        # Calculate even element of matrix predict \n",
    "        # if rate of element identify, element predict unchange\n",
    "        # else select 100 user similarity with user present and rating_diff != 0\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_items):\n",
    "                if ratings[i][j] != 0:\n",
    "                    pred[i][j] = ratings[i][j]\n",
    "                else:\n",
    "#                     index_array_similarity_best = similarity[i].argsort()[-100:-1]\n",
    "                    index_array_similarity_best = [user for user in similarity[i].argsort()[-100:-1] if rating_diff[user][j] != 0]\n",
    "                    if (np.sum(similarity[i][index_array_similarity_best]) == 0):\n",
    "#                         index_item_similary_best = [user for user in similarity[0].argsort()[-1000:-1] if rating_diff[user][111] != 0]\n",
    "#                         pred[i][j] = np.sum(train_matrix_u1_filled.T[j])/n_items\n",
    "                        # tinh rating cua item theo rating trung binh cua cac nguoi su dungj trong bang train cho item\n",
    "#                         index_user_rating_item = np.nonzero(ratings.[i])\n",
    "#                         pred[i][j] = np.sum(ratings[i][index_user_rating_item]) / np.shape(index_user_rating_item)[1]\n",
    "                        pred[i][j] = mean_rating[i]\n",
    "                        continue\n",
    "                    pred[i][j] = similarity[i][index_array_similarity_best].dot(train_matrix_ratings_filled.T[j][index_array_similarity_best]) / np.sum(similarity[i][index_array_similarity_best])\n",
    "            \n",
    "        return pred\n",
    "\n",
    "    # item-item similarity matrix\n",
    "    elif category == 'item':\n",
    "        \n",
    "        # Initialization matrix mean for item mean for user\n",
    "        mean_rating = np.zeros([1682, 1])\n",
    "        \n",
    "        # Create matrix item mean rating\n",
    "        # except case a item don't have rate of user, default mean_rating of item equal 3\n",
    "        for i in range(ratings.T.shape[0]):\n",
    "            sum = 0\n",
    "            num_elements = 0\n",
    "            for j in range(ratings.T.shape[1]):\n",
    "                if ratings.T[i][j] != 0:\n",
    "                    sum = sum + ratings.T[i][j]\n",
    "                    num_elements = num_elements + 1\n",
    "            try:\n",
    "                mean_rating[i] = float(sum) / num_elements\n",
    "            except ZeroDivisionError:\n",
    "                mean_rating[i] = 3\n",
    "                \n",
    "        # Calculate train matrix rating filled \n",
    "        train_matrix_ratings_filled = np.array(ratings.T, copy=True)\n",
    "        for i in range(ratings.T.shape[0]):\n",
    "            for j in range(ratings.T.shape[1]):\n",
    "                if train_matrix_ratings_filled[i][j] == 0:\n",
    "                    train_matrix_ratings_filled[i][j] = mean_rating[i]\n",
    "\n",
    "        # matran rating difference\n",
    "        rating_diff = train_matrix_ratings_filled - mean_rating\n",
    "        if metric == 'cosine':\n",
    "            item_similarity = 1 - pairwise_distances(rating_diff, metric='cosine')\n",
    "        elif metric == 'correlation':\n",
    "            item_similarity = 1 - pairwise_distances(rating_diff, metric='correlation')\n",
    "        #         rating_diff = np.zeros([943, 1682])\n",
    "\n",
    "        # Initialization matrix pred for item-item\n",
    "        pred = np.zeros([n_items, n_users])\n",
    "\n",
    "        # tinh toan ma tran pred theo cong thuc \n",
    "        for i in range(n_items):\n",
    "            for j in range(n_users):\n",
    "                if ratings.T[i][j] != 0:\n",
    "                    pred[i][j] = ratings.T[i][j]\n",
    "                else:\n",
    "                    index_array_similarity_best = [user for user in item_similarity[i].argsort()[-100:-1] if rating_diff[user][j] != 0]\n",
    "                    if (np.sum(item_similarity[i][index_array_similarity_best]) == 0):\n",
    "                        pred[i][j] = mean_rating[i]\n",
    "                        continue\n",
    "                    pred[i][j] = item_similarity[i][index_array_similarity_best].dot(train_matrix_ratings_filled.T[j][index_array_similarity_best]) / np.sum(item_similarity[i][index_array_similarity_best])\n",
    "    return pred.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list matrix train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calculator error RMSE and MAE for element of matrix test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(predict, actual):\n",
    "    predict = predict[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(predict, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def mae(predict, actual):\n",
    "    predict = predict[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return (mean_absolute_error(predict, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test user similarity cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Want show full matrix numpy in ipython notebook\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# # InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "# np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix prediction user-user with similarity cosine\n",
    "user_prediction = np.zeros([943, 1682])\n",
    "\n",
    "# matrix prediction item-item with similarity cosine\n",
    "item_prediction = np.zeros([943, 1682])\n",
    "\n",
    "# matrix prediction item-item with similarity correlation\n",
    "user_prediction_correlation = np.zeros([943, 1682])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80900 1.02421 0.77737 1.00028 1.02421\n"
     ]
    }
   ],
   "source": [
    "# for i, matrix in enumerate(train_list):\n",
    "user_prediction = predict(train_matrix_u5, category='user', metric='cosine')\n",
    "item_prediction = predict(train_matrix_u5, category='item', metric='cosine')\n",
    "\n",
    "#     print(user_prediction)\n",
    "\n",
    "user_prediction_correlation = predict(train_matrix_u5, category='user', metric='correlation')\n",
    "#     item_prediction_correlation = predict(matrix, item_similarity_correlation, type='item')\n",
    "\n",
    "MAE_item = mae(item_prediction, test_matrix_u5)\n",
    "MAE_user = mae(user_prediction, test_matrix_u5)\n",
    "RMSE_item = rmse(item_prediction, test_matrix_u5)\n",
    "RMSE_user = rmse(user_prediction, test_matrix_u5)\n",
    "\n",
    "#     RMAE_item_correlation[i] = rmse(item_prediction_correlation, test_list[i])\n",
    "RMSE_user_correlation = rmse(user_prediction_correlation, test_matrix_u5)\n",
    "print('{0:.5f} {1:.5f} {2:.5f} {3:.5f} {4:.5f}'.format(\n",
    "    MAE_user, RMSE_user, MAE_item, RMSE_item, \n",
    "    RMSE_user_correlation))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0002830775412475\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0242113814633078\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative based model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
